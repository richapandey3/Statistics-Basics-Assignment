# -*- coding: utf-8 -*-
"""Statistics Basics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-P5tpiJlOzKVbCFAJaHTboifIVlprEI5
"""

#1. Q 1. Explain the different types of data (qualitative and quantitative) and provide examples of each. Discuss
#nominal, ordinal, interval, and ratio scales


#ans
1. Types of Data
A. Qualitative Data (Categorical Data)
Definition: Describes non-numeric characteristics or labels.
Examples:
Eye color (blue, green, brown)
Gender (male, female)
Types of cuisine (Italian, Chinese, Indian)
Subtypes:
Nominal Scale:

Definition: Categories with no intrinsic order or ranking.
Examples:
Hair color: Black, brown, blonde
Car brands: Toyota, Ford, Honda
Key Characteristics:
No numeric value or order
Only counts or mode can be applied.
Ordinal Scale:

Definition: Categories that have a meaningful order but not equal intervals between them.
Examples:
Satisfaction levels: Poor, Fair, Good, Excellent
Education level: High school, Bachelor's, Master's, PhD
Key Characteristics:
Order matters.
Differences between values are not measurable or consistent.
B. Quantitative Data (Numerical Data)
Definition: Represents numeric values that quantify something.
Examples:
Height (in centimeters)
Weight (in kilograms)
Test scores (0-100)
Subtypes:
Interval Scale:

Definition: Numeric data with equal intervals between values but no true zero.
Examples:
Temperature in Celsius or Fahrenheit
Calendar years (e.g., 1990, 2000, 2010)
Key Characteristics:
Differences are meaningful.
Ratios are not meaningful (e.g., 20¬∞C is not "twice as hot" as 10¬∞C).
Ratio Scale:

Definition: Numeric data with equal intervals and a true zero point.
Examples:
Weight (e.g., 0 kg means no weight)
Age (e.g., 0 years means no age)
Income (e.g., $0 income)
Key Characteristics:
Ratios are meaningful (e.g., 4 kg is twice as heavy as 2 kg).
Allows for the widest range of statistical operations.
Key Differences Between Scales
Scale	Order	Equal Intervals	True Zero	Examples
Nominal	‚úò	‚úò	‚úò	Hair color, car brands
Ordinal	‚úî	‚úò	‚úò	Education level, satisfaction
Interval	‚úî	‚úî	‚úò	Temperature, calendar years
Ratio	‚úî	‚úî	‚úî	Weight, income, age

#Q.2 What are the measures of central tendency, and when should you use each? Discuss the mean, median,
#and mode with examples and situations where each is appropriate.

#Q3. Explain the concept of dispersion. How do variance and standard deviation measure the spread of data?


1. Key Measures of Dispersion
Range: The difference between the maximum and minimum values.
Range
=
Max¬†value
‚àí
Min¬†value
Range=Max¬†value‚àíMin¬†value
Variance: Measures the average squared deviation from the mean.
Standard Deviation: The square root of the variance, representing the average deviation from the mean in the same units as the data.
2. Variance
Definition: Variance quantifies how far data points are, on average, from the mean. It is a measure of the spread in squared units.

Variance
(
ùúé
2
)
=
‚àë
(
ùë•
ùëñ
‚àí
ùúá
)
2
ùëÅ
(for¬†population¬†data)
Variance(œÉ
2
 )=
N
‚àë(x
i
‚Äã
 ‚àíŒº)
2

‚Äã
 (for¬†population¬†data)
Variance
(
ùë†
2
)
=
‚àë
(
ùë•
ùëñ
‚àí
ùë•
Àâ
)
2
ùëõ
‚àí
1
(for¬†sample¬†data)
Variance(s
2
 )=
n‚àí1
‚àë(x
i
‚Äã
 ‚àí
x
Àâ
 )
2

‚Äã
 (for¬†sample¬†data)
Where:

ùë•
ùëñ
x
i
‚Äã
 : Each data point
ùúá
Œº: Population mean
ùë•
Àâ
x
Àâ
 : Sample mean
ùëÅ
N: Number of population data points
ùëõ
n: Number of sample data points
Example:

Dataset:
10
,
20
,
30
,
40
10,20,30,40
Mean:
ùë•
Àâ
=
25
x
Àâ
 =25
Deviations:
(
‚àí
15
)
,
(
‚àí
5
)
,
(
+
5
)
,
(
+
15
)
(‚àí15),(‚àí5),(+5),(+15)
Squared deviations:
225
,
25
,
25
,
225
225,25,25,225
Variance (sample):
225
+
25
+
25
+
225
4
‚àí
1
=
166.67
4‚àí1
225+25+25+225
‚Äã
 =166.67
3. Standard Deviation
Definition: The square root of variance. It brings the measure of dispersion back to the original units of the data.

Standard¬†Deviation
(
ùúé
)
=
Variance
Standard¬†Deviation(œÉ)=
Variance
‚Äã

Example:

From the above example:
166.67
‚âà
12.91
166.67
‚Äã
 ‚âà12.91
This indicates that, on average, data points deviate by approximately
12.91
12.91 units from the mean.
4. How They Measure Spread
Variance:
Indicates how spread out the data is.
Large variance: Data points are far from the mean.
Small variance: Data points are closer to the mean.
Standard Deviation:
Provides a more intuitive understanding since it uses the same units as the data.
Helps assess the "typical" deviation from the mean.
5. Practical Insights
Low Dispersion:
Example:
10
,
10
,
11
,
10
,
10
10,10,11,10,10
Standard deviation: Small (data points are close to the mean).
High Dispersion:
Example:
1
,
10
,
20
,
40
,
50
1,10,20,40,50
Standard deviation: Large (data points are widely spread).
6. Applications
Comparing Datasets:
Example: Test scores from two classes with the same mean but different standard deviations:
Class A:
ùúé
=
5
œÉ=5 (scores are consistent).
Class B:
ùúé
=
15
œÉ=15 (scores vary widely).
Risk Assessment:
In finance, a higher standard deviation in investment returns indicates greater risk.

#4. What is a box plot, and what can it tell you about the distribution of data?


Central Tendency:

The median indicates the central value of the data.
Spread/Variability:

The length of the box (IQR) reflects the variability in the middle 50% of the data.
Longer whiskers indicate a larger range; shorter whiskers indicate less variability.
Outliers:

Points outside the whiskers are flagged as outliers, helping identify unusual data points.
Symmetry and Skewness:

Symmetric distribution: The median line is near the center of the box, and whiskers are approximately equal in length.
Skewed distribution:
Left-skewed: Median is closer to Q3, with a longer whisker on the left.
Right-skewed: Median is closer to Q1, with a longer whisker on the right.
Comparison Across Groups:

When comparing multiple box plots side by side, differences in medians, spreads, and outliers provide insights into group differences.
Example Interpretation
Dataset:
10
,
12
,
14
,
15
,
16
,
18
,
20
,
25
,
30
,
50
10,12,14,15,16,18,20,25,30,50

Minimum: 10
Q1 (25th percentile): 14.5
Median (Q2): 16.5
Q3 (75th percentile): 25
Maximum: 50
IQR:
ùëÑ
3
‚àí
ùëÑ
1
=
25
‚àí
14.5
=
10.5
Q3‚àíQ1=25‚àí14.5=10.5
Outliers:

Values >
ùëÑ
3
+
1.5
√ó
IQR
=
25
+
15.75
=
40.75
Q3+1.5√óIQR=25+15.75=40.75
Outlier: 50.
The box plot would:

Show a box from 14.5 to 25.
Have a median line at 16.5.
Whiskers extend from 10 to 40.75.
Mark 50 as an outlier.
Advantages of a Box Plot
Provides a clear summary of the data distribution.
Highlights outliers effectively.
Useful for comparing multiple groups.
Limitations
Does not show the exact distribution (e.g., peaks or modality).
Summary statistics may oversimplify the data.


#Q5. Discuss the role of random sampling in making inferences about populations

Why Use Random Sampling?
Representativeness:

A random sample is likely to reflect the characteristics of the entire population, reducing bias.
Generalizability:

Inferences drawn from a random sample can be reliably generalized to the population, assuming the sample is large enough.
Feasibility:

Studying the entire population is often impractical or impossible. Random sampling provides a manageable alternative.
Foundation for Statistical Analysis:

Many statistical methods (e.g., confidence intervals, hypothesis testing) assume data comes from a random sample.
How Random Sampling Enables Inferences
Eliminates Systematic Bias:

By giving each population member an equal chance of selection, random sampling avoids over- or under-representing specific groups.
Supports Probability Theory:

Random sampling allows for the use of probability theory to quantify uncertainty (e.g., sampling error).
Provides the Basis for Estimation:

Statistics computed from a sample (e.g., mean, proportion) can estimate population parameters.
Example: If the sample mean height is 170 cm, this can estimate the population mean height.
Allows for Hypothesis Testing:

Researchers can test claims about the population using sample data.
Example: Testing whether the average income of a population is greater than $50,000 based on a sample.
Key Considerations for Random Sampling
Sample Size:

Larger random samples tend to produce more accurate estimates and reduce sampling error.
Example: A survey with 1,000 respondents is more reliable than one with 50 respondents.
Sampling Error:

Even with random sampling, there is natural variability between the sample and population.
This error can be quantified using confidence intervals or standard errors.
Stratified Random Sampling:

In cases where the population is heterogeneous, dividing it into strata and sampling within each group ensures more accurate representation.
Non-Response or Missing Data:

If a significant portion of randomly selected individuals fails to participate, it may bias the results.
Example of Random Sampling in Practice
Scenario: Estimating the average age of residents in a city of 1 million people.

Without Random Sampling:

Surveying only a specific neighborhood might yield biased results, as residents in that area may not represent the entire city.
With Random Sampling:

Selecting 1,000 residents at random ensures that every individual in the city has an equal chance of being included, leading to a more accurate estimate of the city's average age.
Limitations of Random Sampling
Cost and Logistics:
Random sampling may be expensive or difficult for large populations.
Potential for Bias:
Poor implementation (e.g., not reaching certain groups) can result in biased samples.
Sampling vs. Non-Sampling Errors:
Non-sampling errors, such as measurement errors or incorrect data recording, can affect the results despite proper random sampling.


#6. Explain the concept of skewness and its types. How does skewness affect the interpretation of data?

Eliminates Systematic Bias:

By giving each population member an equal chance of selection, random sampling avoids over- or under-representing specific groups.
Supports Probability Theory:

Random sampling allows for the use of probability theory to quantify uncertainty (e.g., sampling error).
Provides the Basis for Estimation:

Statistics computed from a sample (e.g., mean, proportion) can estimate population parameters.
Example: If the sample mean height is 170 cm, this can estimate the population mean height.
Allows for Hypothesis Testing:

Researchers can test claims about the population using sample data.
Example: Testing whether the average income of a population is greater than $50,000 based on a sample.
Key Considerations for Random Sampling
Sample Size:

Larger random samples tend to produce more accurate estimates and reduce sampling error.
Example: A survey with 1,000 respondents is more reliable than one with 50 respondents.
Sampling Error:

Even with random sampling, there is natural variability between the sample and population.
This error can be quantified using confidence intervals or standard errors.
Stratified Random Sampling:

In cases where the population is heterogeneous, dividing it into strata and sampling within each group ensures more accurate representation.
Non-Response or Missing Data:

If a significant portion of randomly selected individuals fails to participate, it may bias the results.
Example of Random Sampling in Practice
Scenario: Estimating the average age of residents in a city of 1 million people.

Without Random Sampling:

Surveying only a specific neighborhood might yield biased results, as residents in that area may not represent the entire city.
With Random Sampling:

Selecting 1,000 residents at random ensures that every individual in the city has an equal chance of being included, leading to a more accurate estimate of the city's average age.
Limitations of Random Sampling
Cost and Logistics:
Random sampling may be expensive or difficult for large populations.
Potential for Bias:
Poor implementation (e.g., not reaching certain groups) can result in biased samples.
Sampling vs. Non-Sampling Errors:
Non-sampling errors, such as measurement errors or incorrect data recording, can affect the results despite proper random sampling.
Conclusion
Random sampling is essential for making reliable and unbiased inferences about a population. By ensuring each member has an equal chance of selection, it minimizes bias and allows researchers to use statistical methods to quantify uncertainty and test hypotheses. Properly implemented, random sampling forms the foundation of evidence-based decision-making and scientific research.






You said:
6. Explain the concept of skewness and its types. How does skewness affect the interpretation of data?
ChatGPT said:
ChatGPT
Skewness: Concept and Interpretation
Skewness measures the asymmetry of a data distribution around its mean. It indicates whether the data is symmetrically distributed or if it skews more towards one side. A perfectly symmetrical dataset has a skewness of 0, while distributions with more data on one side of the mean exhibit positive or negative skewness.

Types of Skewness
Symmetrical Distribution:

Description: The data is evenly distributed around the mean.
Characteristics:
Mean ‚âà Median ‚âà Mode
Examples: Normal distribution, height distribution in a balanced population.
Skewness: 0.
Positive Skewness (Right-Skewed):

Description: The tail on the right side of the distribution is longer or "heavier."
Characteristics:
Mean > Median > Mode
A small number of larger values pull the mean to the right.
Examples:
Income distribution (a few very high earners).
Time taken to complete a task (most people finish quickly, but a few take much longer).
Skewness: > 0.
Negative Skewness (Left-Skewed):

Description: The tail on the left side of the distribution is longer or "heavier."
Characteristics:
Mean < Median < Mode
A small number of smaller values pull the mean to the left.
Examples:
Age at retirement (most retire at standard ages, with a few retiring earlier).
Test scores (if many perform well, but a few score very low).
Skewness: < 0.
How Skewness Affects Data Interpretation
Central Tendency:

In skewed distributions, the mean is influenced by extreme values and may not represent the central value effectively.
Use the median for a better central measure in skewed datasets.
Spread/Variability:

Skewness affects the standard deviation, as outliers or longer tails can inflate the measure of variability.
Consider using interquartile range (IQR) for skewed data.
Choice of Statistical Methods:

Many statistical methods assume a normal distribution (e.g., parametric tests like t-tests).
For skewed data:
Use non-parametric methods (e.g., Mann-Whitney U test).
Apply data transformations (e.g., logarithmic transformation) to reduce skewness.
Real-World Interpretation:

Positive Skewness Example:
Income data: The mean income may seem high due to a few wealthy individuals, but the median gives a more realistic picture of what most people earn.
Negative Skewness Example:
Test scores: A left-skewed distribution indicates that most students performed well, but a few outliers had very low scores.
Risk Assessment:

In finance, skewness helps assess the risk of investments:
Positive skewness: Potential for high returns but a long right tail indicates rare extreme gains.
Negative skewness: Frequent small gains but a long left tail indicates the risk of rare, significant losses.
Visual Representation
Symmetrical: Bell-shaped curve (normal distribution).
Positive Skewness: Right tail extends farther.
Negative Skewness: Left tail extends farther.
Skewness Formula
The skewness of a dataset can be calculated using:

Skewness
=
ùëõ
(
ùëõ
‚àí
1
)
(
ùëõ
‚àí
2
)
‚àë
(
ùë•
ùëñ
‚àí
ùë•
Àâ
ùë†
)
3
Skewness=
(n‚àí1)(n‚àí2)
n
‚Äã
 ‚àë(
s
x
i
‚Äã
 ‚àí
x
Àâ

‚Äã
 )
3

Where:

ùëõ
n: Number of observations
ùë•
ùëñ
x
i
‚Äã
 : Data values
ùë•
Àâ
x
Àâ
 : Mean
ùë†
s: Standard deviation


#7. What is the interquartile range (IQR), and how is it used to detect outliers

7. What is the interquartile range (IQR), and how is it used to detect outliers
The Interquartile Range (IQR) is a measure of statistical dispersion, which is the spread of the data points. The IQR specifically measures the range within which the central 50% of your data points lie, and is calculated by subtracting the first quartile (Q1) from the third quartile (Q3):

IQR
=
ùëÑ
3
‚àí
ùëÑ
1
Here's a step-by-step process to calculate and use the IQR to detect outliers:

Order the Data: Arrange your data set in ascending order.

Find the Quartiles:

Q1 (first quartile) is the median of the lower half of the data (not including the median if the number of data points is odd).

Q3 (third quartile) is the median of the upper half of the data.

Calculate the IQR: Subtract Q1 from Q3.

Determine Outliers: Data points that fall below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR are considered outliers.

For example, if your data set is:

1
,
2
,
3
,
4
,
5
,
6
,
7
,
8
,
9
,
10
,
11
Q1 (25th percentile) = 3

Q3 (75th percentile) = 9

IQR = 9 - 3 = 6

Outliers are below
ùëÑ
1
‚àí
1.5
√ó
ùêº
ùëÑ
ùëÖ
 or above
ùëÑ
3
+
1.5
√ó
ùêº
ùëÑ
ùëÖ
:

3
‚àí
1.5
√ó
6
=
‚àí
6
9
+
1.5
√ó
6
=
18
So, any data points below -6 or above 18 would be considered outliers.


#Q8. Discuss the conditions under which the binomial distribution is used

7. What is the interquartile range (IQR), and how is it used to detect outliers
The Interquartile Range (IQR) is a measure of statistical dispersion, which is the spread of the data points. The IQR specifically measures the range within which the central 50% of your data points lie, and is calculated by subtracting the first quartile (Q1) from the third quartile (Q3):

IQR
=
ùëÑ
3
‚àí
ùëÑ
1
Here's a step-by-step process to calculate and use the IQR to detect outliers:

Order the Data: Arrange your data set in ascending order.

Find the Quartiles:

Q1 (first quartile) is the median of the lower half of the data (not including the median if the number of data points is odd).

Q3 (third quartile) is the median of the upper half of the data.

Calculate the IQR: Subtract Q1 from Q3.

Determine Outliers: Data points that fall below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR are considered outliers.

For example, if your data set is:

1
,
2
,
3
,
4
,
5
,
6
,
7
,
8
,
9
,
10
,
11
Q1 (25th percentile) = 3

Q3 (75th percentile) = 9

IQR = 9 - 3 = 6

Outliers are below
ùëÑ
1
‚àí
1.5
√ó
ùêº
ùëÑ
ùëÖ
 or above
ùëÑ
3
+
1.5
√ó
ùêº
ùëÑ
ùëÖ
:

3
‚àí
1.5
√ó
6
=
‚àí
6
9
+
1.5
√ó
6
=
18
So, any data points below -6 or above 18 would be considered outliers.

Would you like to try calculating the IQR for a specific data set you have in mind?

8. Discuss the conditions under which the binomial distribution is used
The binomial distribution is a probability distribution that summarizes the likelihood of a value taking one of two independent states and is used under specific conditions. Here are the key conditions:

Fixed Number of Trials: The experiment is repeated a fixed number of times. Each trial is identical and independent of the others.

Only Two Possible Outcomes: Each trial has only two possible outcomes, often referred to as "success" and "failure."

Constant Probability of Success: The probability of success (denoted as
ùëù
) is the same for each trial. Consequently, the probability of failure is
1
‚àí
ùëù
.

Independent Trials: The outcome of one trial does not affect the outcome of any other trial. This independence ensures the probabilities remain constant.

Examples of Binomial Distribution Applications:
Coin Tossing: Tossing a coin a fixed number of times, where the outcomes are heads (success) and tails (failure).

Quality Control: Determining the probability of finding a certain number of defective products in a batch.

Medical Trials: The success rate of a treatment in a fixed number of patients.

Survey Results: The number of people in a survey who respond "yes" to a particular question.

The binomial distribution is particularly useful in scenarios where you're interested in the number of successes out of a fixed number of trials.

#Q9. Explain the properties of the normal distribution and the empirical rule (68-95-99.7 rule)

. Explain the properties of the normal distribution and the empirical rule (68-95-99.7 rule)
Properties of the Normal Distribution
The normal distribution, often known as the Gaussian distribution, is a continuous probability distribution characterized by its symmetrical, bell-shaped curve. Here are the key properties:

Symmetry: The curve is perfectly symmetrical around its mean (Œº). This means that the left side of the curve is a mirror image of the right side.

Mean, Median, and Mode: In a normal distribution, the mean, median, and mode are all equal and located at the center of the distribution.

Asymptotic Nature: The tails of the distribution curve approach the horizontal axis asymptotically. This means they get closer to the axis but never actually touch it.

Defined by Mean and Standard Deviation: The shape and position of the normal distribution are determined by its mean (Œº) and standard deviation (œÉ). The mean determines the center of the distribution, while the standard deviation controls the spread.

Total Area Under the Curve: The total area under the normal distribution curve is equal to 1. This represents the total probability of all possible outcomes.

Empirical Rule: This relates to the 68-95-99.7 rule, which we'll explain next.

Empirical Rule (68-95-99.7 Rule)
The empirical rule is a guideline for understanding the distribution of data in a normal distribution:

68% of the data falls within one standard deviation (œÉ) of the mean (Œº). This means that if you go one standard deviation to the left and one to the right of the mean, you will encompass approximately 68% of the data points.

95% of the data falls within two standard deviations of the mean. So, between Œº - 2œÉ and Œº + 2œÉ, you'll find about 95% of the data points.

99.7% of the data falls within three standard deviations of the mean. This means almost all the data points (99.7%) are contained within Œº - 3œÉ and Œº + 3œÉ.

Here‚Äôs a visual representation to help you understand:

        |____68%____|
  |_________95%_________|
|______________99.7%______________|
These rules are particularly useful for identifying how data is spread out around the mean, and for detecting potential outliers.

#Q10. Provide a real-life example of a Poisson process and calculate the probability for a specific event

Example Scenario:
Imagine a bank where customers arrive at an average rate of 3 per minute. This is an example of a Poisson process, where events (customer arrivals) occur independently and at a constant average rate.

Problem:
What's the probability that exactly 5 customers arrive in a particular minute?

Poisson Distribution Formula:
The Poisson probability formula is given by:

ùëÉ
(
ùëã
=
ùëò
)
=
ùúÜ
ùëò
ùëí
‚àí
ùúÜ
ùëò
!
where:

ùëÉ
(
ùëã
=
ùëò
)
 is the probability of
ùëò
 events in a given interval

ùúÜ
 is the average number of events (3 customers per minute in this case)

ùëò
 is the number of events (5 customers in this case)

ùëí
 is approximately 2.71828 (Euler's number)

Calculation:
Plug in the values into the formula:

ùëÉ
(
ùëã
=
5
)
=
3
5
‚ãÖ
ùëí
‚àí
3
5
!
ùëÉ
(
ùëã
=
5
)
=
243
‚ãÖ
0.0498
120
ùëÉ
(
ùëã
=
5
)
‚âà
0.1008
So, the probability that exactly 5 customers arrive in a minute is approximately 0.1008, or about 10.08%.

#Q11. Explain what a random variable is and differentiate between discrete and continuous random variables

A random variable is a numerical value determined by the outcome of a random phenomenon. It assigns a numerical value to each possible outcome in a sample space. Random variables are fundamental in probability and statistics, as they allow us to quantify and analyze random events.

Types of Random Variables
Discrete Random Variables:

A discrete random variable has a countable number of possible values.

Each value is distinct and separate; there are gaps between values.

Examples include:

The number of heads in a series of coin tosses.

The number of students in a classroom.

The number of defective products in a batch.

Probability Mass Function (PMF): The probability distribution of a discrete random variable is described using a PMF, which provides the probability of each possible value.

Continuous Random Variables:

A continuous random variable has an infinite number of possible values within a given range.

The values can take on any number within a specified interval, including fractions and decimals.

Examples include:

The height of individuals in a population.

The time it takes to complete a task.

The temperature on a given day.

Probability Density Function (PDF): The probability distribution of a continuous random variable is described using a PDF, which indicates the probability of the variable falling within a specific range of values.

Key Differences
Aspect	Discrete Random Variable	Continuous Random Variable
Possible Values	Countable	Uncountable (infinite)
Examples	Number of coins, students, etc.	Height, weight, time, etc.
Probability Distribution	PMF (Probability Mass Function)	PDF (Probability Density Function)
Probabilities	Exact values	Intervals or ranges

#Q.12. Provide an example dataset, calculate both covariance and correlation, and interpret the results

Let's work through a simple example to understand covariance and correlation. We'll use a dataset that shows the relationship between hours studied and exam scores for a group of students.

Example Dataset:
Student	Hours Studied	Exam Score
A	2	50
B	3	60
C	5	80
D	7	85
E	8	90
Step-by-Step Calculations
Calculate the Mean of Each Variable:

Mean of Hours Studied (XÃÑ): $$XÃÑ = \frac{2 + 3 + 5 + 7 + 8}{5} = 5$$

Mean of Exam Scores (»≤): $$»≤ = \frac{50 + 60 + 80 + 85 + 90}{5} = 73$$

Calculate the Covariance: Covariance formula: $$\text{Cov}(X, Y) = \frac{\sum (X_i - XÃÑ)(Y_i - »≤)}{n - 1}$$ where
ùëã
ùëñ
 and
ùëå
ùëñ
 are individual data points, and
ùëõ
 is the number of data points.

Let's calculate:

So, the covariance is 42.5.

Calculate the Correlation Coefficient: Correlation formula: $$r = \frac{\text{Cov}(X, Y)}{œÉ_X œÉ_Y}$$ where
ùúé
ùëã
 and
ùúé
ùëå
 are the standard deviations of X and Y, respectively.

To find the standard deviations:

Variance of X (Hours Studied): $$œÉ_X^2 = \frac{(2-5)^2 + (3-5)^2 + (5-5)^2 + (7-5)^2 + (8-5)^2}{5-1}$$ $$= \frac{9 + 4 + 0 + 4 + 9}{4} = 6.5$$ $$œÉ_X = \sqrt{6.5} \approx 2.55$$

Variance of Y (Exam Scores): $$œÉ_Y^2 = \frac{(50-73)^2 + (60-73)^2 + (80-73)^2 + (85-73)^2 + (90-73)^2}{5-1}$$ $$= \frac{529 + 169 + 49 + 144 + 289}{4} = 295$$ $$œÉ_Y = \sqrt{295} \approx 17.15$$

Now, calculate the correlation:

Interpretation:
Covariance (42.5): Indicates the direction of the relationship between hours studied and exam scores. Since it's positive, it shows that as the number of hours studied increases, the exam scores also tend to increase.

Correlation (0.97): Measures the strength and direction of the linear relationship between two variables. A correlation coefficient close to 1 indicates a very strong positive linear relationship.